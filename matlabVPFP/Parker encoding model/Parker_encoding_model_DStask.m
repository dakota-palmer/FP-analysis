% function[answer]=inscopix_spline_regression(condition,subject)

%one session took ~57min to run at 40hz?
% took ~4min at 10hz ; ~2min at 5hz

%determine if folder exists and if so purge it, if not create it
curr_dir = pwd;
save_folder = 'lasso_regression/pl';
if exist(save_folder)==0
    mkdir(save_folder)
else
    cd(save_folder)
    delete('*')
    cd ../..
end
     
%load a .mat containing preanalyzed FP data generated by our
%fpAnalyzeData.m (mainly to visualize raw peri-cue traces to compare vs.
%normalized peri-cue traces)
load(uigetfile('*.mat')); %choose the subjDataAnalyzed.mat file to open for your experiment %by default only show .mat files



condition = 'data_to_input' %/example';
subjects =  [1,2]%:278; %only one example file was included- I think there should be 1 file per subject...I guess in our case it's 1 per subj -dp


for subject=1:numel(subjects)
    
    clearvars -except curr_dir save_folder condition subjects subject subjDataAnalyzed
    
    tic
    %how much time should you shift back (in seconds)
    time_back_orig=2; %dp 
    time_forward_orig=6;
    
    type1= 'time_shift';  %'spline','time_shift'
    
    shift_con=1;   %Should we shift the stimulus events so they start at 0? %~~~TODO: unclear what this means
    
    %---- Data Extraction-----
    %opens folder to be tested
    file_root=pwd;
    cd(condition)
    
    %creates index of all files in folder
    allitems=dir(pwd);
    f=length(allitems);
    folders_ind=0; 
    
    cd(file_root);
    
    for ind=1:f
        if allitems(ind).name(1)~='I' && allitems(ind).name(1)~='.' && allitems(ind).isdir==0
            folders_ind=folders_ind+1;
            files{folders_ind}=allitems(ind).name; %contains name of each individual .mat
        end 
    end
    
    
    %Load one file corresponding to this subject
    file_name=char(files(subject)); 
    file_name=strcat(condition,'/',file_name);
    load(file_name);
    
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~DOWNSAMPLE TO SAVE TIME WHILE DEBUGGING ~~~~~~~~~~~~~~~~~~~~
%     %Downsample to 5hz from samp_rate
%     figure;
%     subplot(2,1,1); hold on; title('original 465nm');
%     plot(g_output.reblue);
%     
%     g_output.reblue=resample(g_output.reblue,5,g_output.samp_rate);       %Downsample to 5Hz from samp_rate
%     g_output.samp_rate= 5;
%     
%     %now get rid of some first and last point because downsampling introduces extreme changes here?
%     g_output.reblue= g_output.reblue(5:end-4);
%     
%     subplot(2,1,2); hold on; title('downsampled 465nm');
%     plot(g_output.reblue);
% 
%     
    %Convert seconds to hertz (by multiplying timestamp by sampling rate) + isolates conditions 
  
    %DS TASK EVENTS~~~
    DS= output.DS.*g_output.samp_rate;
    NS= output.NS.*g_output.samp_rate;
    
    poxDS= output.firstPoxDS.*g_output.samp_rate; %consider breaking into rewarded/unrewarded 
    loxDS= output.firstLoxDS.*g_output.samp_rate;
%     out= output.out; %.*g_output.samp_rate;
    
    %Normalize gcamp signal by the max -- COMMENT OUT WHEN NOT NEEDED
    %TODO: dp- looks like the third option here uses a simple mean and std for
    %the whole GCaMP trace... we could use a rolling
    %calculation instead?
    
    % gcamp_y=g_output.reblue;
    % gcamp_y=g_output.reblue./max(g_output.reblue
%     gcamp_y=(g_output.reblue-mean(g_output.reblue))./std(g_output.reblue); fprintf('Z-scored \n')
    
    %TRYING OTHER NORMALIZATION METHODS
             %matlab's built in moving median function
         %inspired by(Patel, McAlinden, Matheison, &
         %Sakata, 2019 BioRxiv) but not really what they did
    rollingMedianBlue= movmedian(g_output.reblue,800);
    rollingMeanBlue= movmean(g_output.reblue,800);
    
    %perhaps Std should be rolling or just based off first couple seconds (representative only of spontaneous noise)?
    rollingStdBlue= movstd(g_output.reblue,800);
    stdBlueNoise= std(g_output.reblue(1:g_output.samp_rate)); %first second
    
    dffblue= (g_output.reblue-rollingMedianBlue)./rollingMedianBlue;
%     zblueMedian= (g_output.reblue-rollingMedianBlue)./std(rollingMedianBlue); %simple std

    zblueMedian= (g_output.reblue-rollingMedianBlue)./rollingStdBlue; %rolling Std
%     zblueMedian= (g_output.reblue-rollingMedianBlue)./stdBlueNoise;   %simple beginning noise std

    
      %Parker et al 2019 actually used CNFE algorithm to infer spiking
    %activity, then took spike rate probability, smoothed with gaussian
    %filter, and normalized by peak of avg spike rate probability
    
    %in 2016,: Data were post-processed in MATLAB using a high-pass FIR filter with a passband of 0.4 Hz, stopband of 0.1 Hz and a stopband attenuation of 10 dB to remove the baseline fluorescence and correct for drift in the baseline. dF/F was calculated by dividing the high-pass filtered signal by the mean of the signal before high-pass filtering. To compare signal across recording sites, the z-score of dF/F was calculated by dividing each recording site's dF/F trace by its s.d.
    %To compare signal across recording sites, the z-score of dF/F was calculated by dividing each recording site's dF/F trace by its s.d.
    
%     filterBuilder(); %hi pass; %passband 0.4Hz ; stopband 0.1 Hz ; stopband attenuation 10dB
%     
%     pause();
%     
%     reblueFiltered= filter(Hhp, g_output.reblue);
%     
%     dffFiltered= reblueFiltered/mean(g_output.reblue);
%     
%     dffZ= dffFiltered/std(dffFiltered);
%     
%     figure;
%     subplot(4,1,1); hold on; title('signal');
%     plot(g_output.reblue);
%     subplot(4,1,2); hold on; title('filtered signal');
%     plot(reblueFiltered);
%     subplot(4,1,3); hold on; title('dff filtered signal (filtered/mean unfiltered)');
%     plot(dffFiltered);
%     subplot(4,1,4); hold on; title('z scored dff filtered (dff/std(dff)');
%     plot(dffZ);
%     
    
%     %trying to present as relative % of peak
%     %should probably be done after making baseline stable
% %     peak= max(g_output.reblue);
%     peak = max(zblueMedian);
% %     reblueRelPeak= g_output.reblue/peak;
%     reblueRelPeak= zblueMedian/peak;
%     figure; hold on; title('rel peak');
%     plot(reblueRelPeak);

    figure();
    subplot(4,1,1);
    title('blue moving median')
    hold on;
    plot(g_output.reblue);
    plot(rollingMedianBlue, 'k');
    subplot(4,1,2);
    title('blue moving mean');
    hold on;
    plot(g_output.reblue);
    plot(rollingMeanBlue, 'k');
    subplot(4,1,3);
    hold on;
    title('blue dF/F (value-median/median)');
    plot(dffblue);
    subplot(4,1,4);
    hold on;
    title('blue z score median (value-median/std(median))')
    plot(zblueMedian);
    
    gcamp_y = zblueMedian; fprintf('z scored based on moving median');
%     gcamp_y= dffblue; fprintf('dff blue based on moving median');
%     gcamp_y= dffZ; fprintf('z scored filtered dff like in 2016 paper'); 
    
    %visualizing normalized trace- dp
    figure; 
    subplot(2,1,1); hold on; title('raw'); 
    plot(g_output.reblue);
    subplot(2,1,2); hold on; title('z scored');
    plot(gcamp_y);
        
    %visualizing event times
    plot(DS, ones(size(DS)), 'k.')
    plot(NS, ones(size(NS))*-1, 'g.')
    plot(poxDS, ones(size(poxDS))*2, 'c.')
    plot(loxDS, ones(size(loxDS))*3, 'r.')
    legend('465','DS', 'NS', 'poxDS', 'loxDS');
    
    
    % ~~~~~ Visualize raw vs normalized peri-cue traces ~~~~~~~~~~~~~
    
    % parameters for time locking
    preCueTime= 5; %t in seconds to examine before cue
    postCueTime= 10; %t in seconds to examine after cue
    
    fs= g_output.samp_rate;
    
    preCueFrames= preCueTime*fs;
    postCueFrames= postCueTime*fs;

    periCueFrames= preCueFrames+postCueFrames;
    
    slideTime = 400; %define time window before cue onset to get baseline mean/stdDev for calculating sliding z scores- 400 for 10s (remember 400/40hz ~10s)

    
    % Timelock to DS

        currentSubj= subjDataAnalyzed.(metadata.subject{1}); %use this for easy indexing into the curret subject within the struct
        
        allDates= [currentSubj.date]; %extract dates as array (easier to search for matching date than struct field)
        
        session= find(allDates== metadata.date); %find session with matching date
        
        %In this section, go cue-by-cue examining how fluorescence intensity changes in response to cue onset (either DS or NS)
        %Use an event-triggered sort of approach viewing data before and after cue onset where time 0 = cue onset time
        %Also, a sliding z-score will be calculated for each timepoint like in (Richard et al., 2018)- using data comprising 10s prior to that timepoint as a baseline  

        disp(strcat('running DS-triggered analysis subject_',  metadata.subject{1}));

        cutTime = []; %this is cleared between sessions to prevent spillover
        
        periDSstarts= []; %start times for all peri-DS windows %cleared between sessions
        periDSends= []; %end times for all peri-DS windows %cleared between sessions

        cutTime= currentSubj(session).raw.cutTime; %save this as an array, greatly speeds things up because we have to go through each timestamp to find the closest one to the cues

        DSskipped= 0;  %counter to know how many cues were cut off/not analyzed (since those too close to the end will be chopped off- this shouldn't happen often though)

        currentSubj(session).DSshifted= interp1(cutTime,cutTime, currentSubj(session).periDS.DS, 'nearest'); %get nearest timestamp in cutTime to actual DS onset
        
                   %NORMALIZE photometry signal (z-score)
            %Here, we will do a rolling z score through the whole time series
            %BUT in each peri-cue period we will use a constant pre-cue baseline mean & std to calculate z score (trial) timelock
                        
            %First, calculate rolling z score for whole trace (later on we'll loop
            %through cues replace peri-cue timestamps for simplicity)
            movingWindowFrames= 10*fs; %time to include in moving window / fs  
            
            rollingMeanBlue= movmean(g_output.reblue,movingWindowFrames); %moving mean
            rollingStdBlue= movstd(g_output.reblue,movingWindowFrames); %moving std
                
            gcamp_normalized= (g_output.reblue-rollingMeanBlue)./rollingStdBlue; %now z scored trace simply based on moving baseline
                
            %adding visualization of 1) raw trace 2) simple moving baseline
            %normalized trace and (later) 3) cue-adjusted moving baseline
            %normalized trace
            figure;
            subplot(3,1,1); hold on; title('raw');
            plot(g_output.reblue);
            subplot(3,1,2); hold on; title('simple moving baseline z score');
            plot(gcamp_normalized);
            
        
            %Next, we'll loop through each cue, getting a pre-cue baseline
            %and calculating z score from this baseline throughout the
            %peri-cue period
        for cue=1:length(currentSubj(session).periDS.DS) %DS CUES %For each DS cue, conduct event-triggered analysis of data surrounding that cue's onset

            %each entry in DS is a timestamp of the DS onset 
            DSonset =  find(cutTime==currentSubj(session).DSshifted(cue));

            %define the frames (datapoints) around each cue to analyze
            preEventTimeDS = DSonset-preCueFrames; %earliest timepoint to examine is the shifted DS onset time - the # of frames we defined as periDSFrames (now this is equivalent to 20s before the shifted cue onset)
            postEventTimeDS = DSonset+postCueFrames; %latest timepoint to examine is the shifted DS onset time + the # of frames we defined as periDSFrames (now this is equivalent to 20s after the shifted cue onset)

            if preEventTimeDS< 1 %if cue onset is too close to the beginning to extract preceding frames, skip this cue
                disp(strcat('****DS cue ', num2str(cue), ' too close to beginning, continuing'));
                DSskipped= DSskipped+1;
                continue
            end

            if postEventTimeDS> length(currentSubj(session).raw.cutTime)-slideTime %%if cue onset is too close to the end to extract following frames, skip this cue; if the latest timepoint to examine is greater than the length of our time axis minus slideTime (10s), then we won't be able to collect sufficient basline data within the 'slideTime' to calculate our sliding z score- so we will just exclude this cue
                disp(strcat('****DS cue ', num2str(cue), ' too close to end, continuing'));
                DSskipped= DSskipped+1;  %iterate the counter for skipped DS cues
                continue %continue out of the loop and move onto the next DS cue
            end
            
            %get peri-cue data from normalized trace (gcamp_y)
%             currentSubj(session).deconvolution.periDS.DSzblueNormalized(:,:,cue)= gcamp_y(preEventTimeDS:postEventTimeDS)
      

            %Here, we will identify timesstamps within the peri-cue period
            %whose z scores should be recalculated based on pre-cue
            %activity alone (tsToNormalize), then we'll calculate z score for these timestamps based on the pre-cue baseline 
            tsToNormalize= []; %reset between cues
            
                %For now this is just pulling the same baselines used in
                %fpAnalyzeData.m , but we might want to adjust
                
                %we've normalized all timestamps above, now go into
                %peri-cue periods and replace those values with values used
                %in heatplots
            tsToNormalize= [find(currentSubj(session).raw.cutTime==currentSubj(session).periDS.periDSwindow(:,1,cue)):find(currentSubj(session).raw.cutTime==currentSubj(session).periDS.periDSwindow(:,end,cue))];

            gcamp_normalized(tsToNormalize)= (g_output.reblue(tsToNormalize)-currentSubj(session).periDS.baselineMeanblue(cue))/currentSubj(session).periDS.baselineStdblue(cue);
            
            %save new peri-cue data from normalized trace (with same
            %parameters, these timestamps should look the same)
            currentSubj(session).deconvolution.periDS.DSzblueNormalized(:,:,cue)= gcamp_normalized(preEventTimeDS:postEventTimeDS);
            
            %for visualizing cue periods, save pre & postEventTimeDS
            %(should help ID if sudden changes are being introduced)
            periDSstarts= [periDSstarts, preEventTimeDS]; %cat start into this array
            periDSends= [periDSends, postEventTimeDS]; %cat end into this array
            

            
%             % Calculate average baseline mean&stdDev 10s prior to DS for z-score
%             %RAW blueA  
%             baselineMeanblue=nanmean(currentSubj(session).raw.reblue((DSonset-slideTime):DSonset)); %baseline mean blue 10s prior to DS onset for boxA
%             baselineStdblue=std(currentSubj(session).raw.reblue((DSonset-slideTime):DSonset)); %baseline stdDev blue 10s prior to DS onset for boxA
%             %RAW purpleA
%             baselineMeanpurple=nanmean(currentSubj(session).repurple((DSonset-slideTime):DSonset)); %baseline mean purple 10s prior to DS onset for boxA
%             baselineStdpurple=std(currentSubj(session).repurple((DSonset-slideTime):DSonset)); %baseline stdDev purple 10s prior to DS onset for boxA
% 
%                 %z score calculation: for each timestamp, subtract baselineMean from current photometry value and divide by baselineStd
%             subjDataAnalyzed.(subjects{subj})(session).periDS.DSzblue(:,:,cue)= (((currentSubj(session).reblue(preEventTimeDS:postEventTimeDS))-baselineMeanblue))/(baselineStdblue); 
%             subjDataAnalyzed.(subjects{subj})(session).periDS.DSzpurple(:,:,cue)= (((currentSubj(session).repurple(preEventTimeDS:postEventTimeDS))- baselineMeanpurple))/(baselineStdpurple);
% 
% 
%             %dff - *******Relies upon previous photobleaching/baseline section
%             subjDataAnalyzed.(subjects{subj})(session).periDS.DSbluedff(:,:,cue)= subjDataAnalyzed.(subjects{subj})(session).photometry.bluedff(preEventTimeDS:postEventTimeDS);
%             subjDataAnalyzed.(subjects{subj})(session).periDS.DSpurpledff(:,:,cue)= subjDataAnalyzed.(subjects{subj})(session).photometry.purpledff(preEventTimeDS:postEventTimeDS);
% 
%             %lets save the baseline mean and std used for z score calc- so
%             %that we can use this same baseline for other analyses
%             subjDataAnalyzed.(subjects{subj})(session).periDS.baselineMeanblue(1,cue)= baselineMeanblue;
%             subjDataAnalyzed.(subjects{subj})(session).periDS.baselineStdblue(1,cue)= baselineStdblue;
%             subjDataAnalyzed.(subjects{subj})(session).periDS.baselineMeanpurple(1,cue)= baselineMeanpurple;
%             subjDataAnalyzed.(subjects{subj})(session).periDS.baselineStdpurple(1,cue)= baselineStdpurple;
% 
%             %save timeLock time axis
%             subjDataAnalyzed.(subjects{subj})(session).periDS.timeLock= [-preCueFrames:postCueFrames]/fs;
% 

        end %end DS cue loop
        
         %finish earlier plot
        subplot(3,1,3); hold on; title('cue-adjusted moving baseline z score');
        plot(gcamp_normalized);
        %overlay vertical line for peri-cue start and end times to visualize cue periods
        %(should help ID if this method introduces sudden shifts)
        for DS= 1:numel(periDSstarts)
           plot([periDSstarts(DS), periDSstarts(DS)], ylim, 'g--');
           plot([periDSends(DS), periDSends(DS)], ylim, 'r--');
        end
        legend('465', 'periDS start', 'periDS end');
        
        gcamp_y= gcamp_normalized;

        figure; sgtitle('Raw vs Normalized peri-DS trace');
        subplot(2,1,1); hold on; title('Raw peri-DS');
        plot(squeeze(currentSubj(session).periDS.DSzblue), 'b--');
        plot(currentSubj(session).periDS.DSzblueMean, 'r', 'LineWidth', 2);

        subplot(2,1,2); hold on; title('Normalized peri-DS');
        plot(squeeze(currentSubj(session).deconvolution.periDS.DSzblueNormalized), 'b--');
        plot(mean(currentSubj(session).deconvolution.periDS.DSzblueNormalized,3), 'r', 'LineWidth', 2);
        
        


            
            
    % ~~~~~~~~ prep for regression ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
    % %Event modulation for initial submission % ~looks like this is where
    % events to be included in the model are defined (and what time window
    % should be used for timelocking (1 for stimulus, 0 for action event?)
    cons={'DS','NS','poxDS','loxDS'};%...
       % 'out'};
    con_shift=[1, 1, 0, 0]; %stimulus events time window is 0:8s, action events it is -2:6s, this defines when to time-lock
    
    %---- Regression data prep ----
    
    %Initialize x-matrices
    con_iden=[];
    x_basic=[];    %No interaction terms, simply event times
    event_times_mat=[];
    num_bins=numel(gcamp_y); %number of time bins
    
    figure; 
    subplot(2,1,1); hold on; title('con times');
    plot(gcamp_y);
    plot(DS, ones(size(DS)*1), 'k.')
    plot(NS, ones(size(NS))*2, 'g.')
    plot(poxDS, ones(size(poxDS))*3, 'c.')
    plot(loxDS, ones(size(loxDS))*4, 'r.')
    legend('465','DS', 'NS', 'poxDS', 'loxDS');
    
    subplot(2,1,2); hold on; title('con binned'); %FOR VISUALIZING CON_TIMES %dp
    plot(gcamp_y);
    conColors= {'k','g','c','r'};
    
    for con=1:numel(cons) %for each event type (condition) included in the model
        
        if con_shift(con)==1 & shift_con==1 %if this is a STIMULUS event (con_shift==1), don't include timestamps before stimulus
            time_back=0;
            time_forward=time_back_orig+time_forward_orig;
        else %Otherwise, if this is an ACTION event (con_shift==0), include both before and after timestamps 
            time_back=time_back_orig;
            time_forward=time_forward_orig;
        end
        
        %gets matrix of event times (in hertz)
        con_times=eval(cons{con}); %Retrieve event timings for this event type (con) by evaluating the variable (with the same name as cons{con}) that was created above in this script
        
        %Gets rid of abandonded trials
        con_times(isnan(con_times))=[]; %~~for us isnan() instead of ==0
        
        %Creates vector with binary indication of events (reset between event types (con))
        con_binned=zeros(1,num_bins); %create empty matrix with 0 for all timestamps
            %make =1 when event occurs
        con_binned(int32(con_times))=1; %~~dp unclear why int32() was used here-maybe to save memory? results seem same as below
%         con_binned(con_times)=1;
     
    %visualizing binary coded event times
        plot(find(con_binned==1), ones(size(find(con_binned==1)))*con, strcat(conColors{con},'.'))      
        
    
        if strcmp(type1,'spline')==1 %IF running in spline mode
            con_binned=circshift(con_binned,[0,-time_back*g_output.samp_rate]);
            event_times_mat=vertcat(event_times_mat,con_binned);
            gcamp_temp=gcamp_y;
            
            %preloads basis set
            load('ben_81x25.mat')
            
            %OR
            
            %makes basis_set
%                         num_set=15;
%                         set_length=(time_back+time_forward)*g_output.samp_rate+1;
%                         basistest=create_bspline_basis([0,set_length],num_set,4);  %Nathan says old fxn -- dp
%                         basis_set=getbasismatrix(1:set_length,basistest); basis_set=full(basis_set); %Nathan says old fxn -- dp
            
            %convolves time series of events with basis sets
            for num_sets=1:numel(basis_set(1,:));
                temp_conv_vec=conv(con_binned,basis_set(:,num_sets)); %dp 'the predictors in our model, Xjk, were generated by convolving the behavioral events with a spline basis set to enable temporally delayed version of the events
                x_basic=horzcat(x_basic,temp_conv_vec(1:numel(con_binned))');
            end
            con_iden=[con_iden ones(1,size(basis_set,2))*con];
            
            %NORMAL REGRESSION
        elseif strcmp(type1,'time_shift')==1 %IF running in time shifted mode
            x_con=[];
            shift_back=g_output.samp_rate*time_back;   %how many timestamps do I shift backwards
            shift_forward=g_output.samp_rate*time_forward; %how many timestamps do I shift forwards
            %             gcamp_temp=gcamp_y(shift_forward+1:end-shift_back);
            gcamp_temp=gcamp_y;
            
            %             for shifts = 1:shift_back+shift_forward+1
            %                 x_con=horzcat(x_con,con_binned(shift_back+shift_forward+2-shifts:end-shifts+1)').
            circTest= 1:36609; %trying to visualize circshift() process; this is analogous to con_binned
            circShiftTest= [];%trying to visualize circshift() process; this is analogous to x_con
             for shifts = -shift_back:shift_forward %Loop over each relative timestamp index (shift) 
                 %I think circularly shifting (circshift()) is  used as way
                 %to implement time shifts relative to event onset...
                 %Basically if shift=0, event times = actual event onset, if
                 %shift= -1, event times= actual event onsets-1 etc....
                 %So at the end of all of this, we're running a regression
                 %for every SHIFT of event timings?
                 ...start with a 1x 36609 (1x num_bins) binary coded vector of
                 %event timings, After 1 event type loop end with an 81 x 36609 (num shifts x num_bins) binary coded
                 %matrix... 81 = number of shifts 
                 %of event timings 
                 %recall that con_binned is a binary vector of event timings (1 where event occurs, otherwise 0)
                x_con=horzcat(x_con,circshift(con_binned,[0,shifts])');
                circShiftTest= horzcat(circShiftTest, circshift(circTest,[0,shifts])'); %just visualizing
             end
            
            %collect all event type data together by cat() this event type's binary coded data (x_con) with previous (x_basic)
            x_basic=horzcat(x_basic,x_con); %x_con ((num event types x num shifts) x num_bins binary matrix of event timings)
            con_iden=[con_iden ones(1,size(x_con,2))*con]; % 1 x (num shifts * num event types) vector ; simply a label of event type (con)
        end
    end
    legend([{'465'},cons]); %for visualizing binary coded event times
    
    %Merges CS+ and Rew
    if max(con_iden)==7 && strcmp(cons{5},'CS')==1
        con_iden(con_iden==7)=6;
    end
    
        %the mean_center() function here goes through every column (every time shift) of x_basic, gets a mean value for that shift (should be the same for every shift of the same event type?) then goes through every row (time bin) and subtracts this mean from actual value (0 or 1) of x_basic
        %so there should be + values only when event occurred (1-mean)??
%     x_all=mean_center(x_basic); %num time bins x (num event types*num shifts) matrix 

    x_all = x_basic; %trying without mean_center (just 0 and 1s)

    gcamp_y=gcamp_temp;
    
    % ~~~~~~~~~~~~~~~ Run regression ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    %result of LASSO here is (num event types * num shifts) x lambda matrix of b coefficients, stats.beta 
        %so each column of x_all is a shifted version of the (mean_center) of event timings
    [stats.beta,stats.p]= lasso(x_all,gcamp_y','cv',5);    %Lasso with cross-validation
    sum_betas=max(stats.beta(:,stats.p.IndexMinMSE));    %Selects betas that minimize MSE
    if sum_betas==0; stats.p.IndexMinMSE=max(find(max(stats.beta)>0.0001)); end  %Makes sure there are no all zero betas
    %cat ing intercept here , so size= (num event types * num shifts) +1 x 1 column vector of betas 
    b=[stats.p.Intercept(stats.p.IndexMinMSE) ; stats.beta(:,stats.p.IndexMinMSE)];  %selects betas based on lambda
    
    %Save file
    long_name=char(files(subjects(subject)));
    dot_stop=find(long_name=='.');
    save_name=long_name(1:dot_stop-1);
    samp_rate=g_output.samp_rate;
    
    cd(save_folder)
    save(save_name,'b');
    cd(curr_dir)
    toc
    
    %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Kernel calculation & vis~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    %above code calculates b, which we can use to calculate event kernels
    
    %if in spline mode, use eq 4 from 2019 preprint
    %if in time shift mode, simply use regression coefficients as kernel (I think that's what they did in 2016 paper)
        
    k= con; %the number of event types
    
    if strcmp(type1,'spline')==1 %if in spline mode
         % Bjk = regression coeff for jth spline basis fxn and kth behavioral event
         % Sj= jth spline basis fxn at time point i with length of 81 time bins
        for eventType = 1:k

             %for indexing rows of b easily as we loop through event types and build kernel, keep track  of timestamps (ts) that correspond to this event type 
              if eventType==1
                splineThisEvent= 2:(numel(b)/k)+1; %skip first index (intercept)
              else
                splineThisEvent= splineThisEvent(end)+1:splineThisEvent(end)+(numel(b)/k); 
              end

           sumTerm= []; %clear between event types
               
           %summation loop over all degrees of freedom (Nsp) of each spline basis
           %set; on each iteration take product of Bjk * Sj(ts) ; sum the
           %results
           for ts= 1:size(basis_set,1)  %loop through ts; using 'ts' for each timestamp instead of 'i' in formula
               for j= 1:size(basis_set,2) %loop over each df of spline basis function
                   sumTerm(ts,j)= b(splineThisEvent(j))*basis_set(ts,j); %save data to be summed at end of loop
               end
           end
          kernel(:,eventType)= (sum(sumTerm,2));  %kernel with row=ts (or spline set) ; column=event type           
        end
        
        %visualize
%         timeLock= linspace(0,size(kernel,1)/g_output.samp_rate, size(kernel,1)); %x axis in s
        timeLock= linspace(-time_back, time_forward, size(kernel,1));

        figure; hold on;
        title('kernels (spline)');
        plot(timeLock,kernel);
        ylabel('regression coefficient b?');
        xlabel('time (s)');
        legend(cons);
        
         %separate plot of stim vs action events
        figure; hold on;
        title(strcat(char(files(subject)),'-kernels (spline)'));
        subplot(2,1,1); hold on; title('stimulus events');
        timeLock= linspace(0, time_back+time_forward, size(kernel,1)); %x axis starts at 0
        plot(timeLock, kernel(:,con_shift==1));
        ylabel('regression coefficient b');
        xlabel('time(s)');
        legend(cons(con_shift==1));
        
        subplot(2,1,2); hold on; title('action events');
        timeLock= linspace(-time_back, time_forward, size(kernel,1)); %x axis starts at -time_back
        plot(timeLock, kernel(:,con_shift==0));
        legend(cons(con_shift==0));

    elseif strcmp(type1, 'time_shift')==1
            %if in timeshift mode, references to 'ts' below are timestamps
        for eventType = 1:k
             %for indexing rows of b easily as we loop through event types and build kernel, keep track  of timestamps (ts) that correspond to this event type 
              if eventType==1
                tsThisEvent= 2:(numel(b)/k)+1; %skip first index (intercept)
              else
                tsThisEvent= tsThisEvent(end)+1:tsThisEvent(end)+(numel(b)/k); 
              end

           sumTerm= []; %clear between event types

           for ts= 1:(numel(b)/k) %loop through ts; using 'ts' for each timestamp instead of 'i'
%                %this seems to fit- there should be 81 time bins in the example data x 7 event types ~ 567      
                kernel(ts,eventType) = b(tsThisEvent(ts));
           end
        end
        
        %visualize
%         timeLock= linspace(0,size(kernel,1)/g_output.samp_rate, size(kernel,1)); %x axis in s
        timeLock= (-shift_back:shift_forward)/g_output.samp_rate; %x axis in s

%         figure; hold on;
%         title('kernels (time shift)');
%         ylabel('regression coefficient b');
%         xlabel('time (s)');
%         plot(timeLock,kernel);
%         legend(cons);
        
        %maybe this is the appropriate way to visualize?
%         timeLock= (-shift_back:shift_forward)/g_output.samp_rate;

        %each point really represents regression coefficient of a shifted
        %version of event timestamps with the same GCaMP signal. For example,
        %a high regression coefficient at +4s means that if you shift all
        %of this event's timestamps forward by +4s the correlation with
        %GCaMP is high. This might suggest an event-induced change in GCaMP activity
        %observed 4s after event onset
        
        figure; hold on;
        title(strcat(char(files(subject)),'-kernels (time shift)'));
        ylabel('regression coefficient b');
        xlabel('time shift of events relative to actual event onsets (s)');
        plot(timeLock,kernel);
        legend(cons);
        
        %separate plot of stim vs action events
        figure; hold on;
        title(strcat(char(files(subject)),'-kernels (time shift)'));
        subplot(2,1,1); hold on; title('stimulus events');
        timeLock= (0:shift_back+shift_forward)/g_output.samp_rate; %x axis starts at 0
        plot(timeLock, kernel(:,con_shift==1));
        ylabel('regression coefficient b');
        xlabel('time shift of events relative to actual event onsets (s)');
        legend(cons(con_shift==1));
        
        subplot(2,1,2); hold on; title('action events');
        timeLock= (-shift_back:shift_forward)/g_output.samp_rate; %x axis starts at -shift_back
        plot(timeLock, kernel(:,con_shift==0));
        legend(cons(con_shift==0));

    end
    
end
